\subsection{Label-switching problem} \label{fdmm-relable-subsect}
An open problem that arises when taking a Bayesian analysis of finite mixture models is \emph{label-switching}. This happens because the model parameters $(\pi_{1},...,\pi_{k},\theta_{1},...,\theta_{k})$ and the latent variables $(z_{1},...,z_{N})$ are unidentifiable, since we can permute the hidden labels without affecting the likelihood function. And when the prior distribution is also invariant to these permutations, the posterior distribution will be invariant too \citep{Rufo2006}.

This issue, becomes a major problem when summarizing the full joint posterior distribution by its marginal distributions, as in the case of Gibbs sampling. For example, when trying to estimate quantities of interest by computing the posterior mean (\ie taking Monte Carlo average), if we do not solve the (possible) label-switching problem, it would lead to nonsensical answers \citep{Stephens2000}. 

The most common approach to remove the label switching problem is to impose artificial \emph{identifiability constraint} on the parameter space, \eg $\pi_{1} < \pi_{2} < ... < \pi_{k}$ as it was proposed by \citet{Richardson1997}. Even though this approach breaks the symmetry of the prior distribution, it does not always work, since for different data sets the imposed identifiability constraints may be ineffective to remove the posterior symmetry \citep{Celeux2000}. Furthermore, it should be noted that this technique does not scale to high dimensions. 

Another approach, is to use \emph{relabelling algorithms}, that is to search for a permutation of the hidden labels that will result in minimizing a posterior loss function. \citet{Stephens2000} proposed a relabelling algorithm, that tries to permute the hidden labels of the MCMC output in such a way that the marginal posterior of each parameter is, as far as possible, unimodal. The drawback of this problem is that is slow and requires to store the posterior responsibilities at each MCMC simulation step. 
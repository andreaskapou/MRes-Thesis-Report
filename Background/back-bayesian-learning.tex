\section{Bayesian Learning} \label{bayesian-learning-section}
There are two broad interpretations of probability theory which are called \emph{frequentist} (or \emph{physical}) and \emph{Bayesian} (or \emph{evidential}) probabilities. In the frequentist approach the parameters, which will be denoted by $\Theta$, are considered to be fixed. The parameter values are inferred by an estimator, \eg Maximum Likelihood Estimator (MLE), and we get error bars for these estimates by considering a distribution over datasets $\mathbf{X}$ \cite[Ch. 1]{Bishop2006}. 

On the other hand, in Bayesian statistics, probabilities provide a quantification of uncertainty or degrees of belief supported by the available evidence. In this setting, the dataset $\mathbf{X}$ is observed and hence is fixed, and we express our uncertainty in the model parameters, by considering the parameters themselves as random variables \cite[Ch. 1]{Bishop2006}. Our initial beliefs about $\Theta$, before observing the data, are represented by a \emph{prior} probability distribution $p(\Theta)$. The effect of observing the data $\mathbf{X}$ is given through the \emph{likelihood} function $p(\mathbf{X}|\Theta)$, which is also referred to as the observation model. The likelihood function expresses how probable are the observed data given the parameters, and is a function of the parameters. Hence, to update our beliefs about the value of $\Theta$, after observing the data $\mathbf{X}$, we use the machinery of probability theory, and more specifically Bayes' theorem, to evaluate the \emph{posterior} probability distribution:
\begin{equation}
  \begin{aligned}
	p(\Theta | \mathbf{X}) & = \frac{p(\mathbf{X}|\Theta) p(\Theta)}{p(\mathbf{X})} %\\
	%& = \frac{p(\mathbf{X}|\Theta) p(\Theta)}{\int p(\mathbf{X}|\Theta) p(\Theta) d\Theta}
  \end{aligned}
\end{equation}
where $p(\mathbf{X}) = \int p(\mathbf{X}|\Theta) p(\Theta) d\Theta$ is called the \emph{evidence} or \emph{marginal likelihood}, since the model parameters are marginalized out (\ie integrated out). Thus, Bayes' theorem can be interpreted as follows:
\begin{equation}
	posterior = \frac{likelihood \times prior}{evidence}
\end{equation}

For completeness, below are shown the main approaches for parameter estimation.
\subsubsection*{ML Estimation of $\Theta$}
Under the Maximum Likelihood approach we seek the value of $\Theta$ that maximizes the likelihood, that is:
\begin{equation} \label{MLE-f-bayes}
	\hat{\Theta} =  \underset{\Theta}{\operatorname{argmax}} \; p(\mathbf{X}|\Theta)
\end{equation}
\subsubsection*{MAP Estimation of $\Theta$}
Under the Maximum a Posteriori approach we seek the value of $\Theta$ that maximizes the posterior $p(\Theta | \mathbf{X})$, that is:
\begin{equation} \label{MAP-f-bayes}
  \begin{aligned}
	\hat{\Theta} & =  \underset{\Theta}{\operatorname{argmax}} \; p(\Theta | \mathbf{X}) \\
	& \propto \underset{\Theta}{\operatorname{argmax}} \; p(\mathbf{X}|\Theta) p(\Theta)
  \end{aligned}
\end{equation}
where the evidence $p(\mathbf{X})$ can be ignored since it does not depend on $\Theta$. Thus, MAP estimation, in contrast to ML, incorporates in the model our prior beliefs regarding the values of the parameters.
\subsubsection*{Bayesian Estimation of $\Theta$}
Under a full Bayesian approach we compute the posterior distribution over the parameters, that is:
\begin{equation} \label{posterior-f-bayes}
  \begin{aligned}
	p(\Theta | \mathbf{X}) = \frac{p(\mathbf{X}|\Theta) p(\Theta)}{p(\mathbf{X})} 
  \end{aligned}
\end{equation}

Thus, in the Bayesian framework instead of estimating a fixed value for the parameters, we also capture the uncertainty of the estimation by computing the posterior distribution of the parameters. On the other hand, ML or MAP estimations involve in finding an optimum point estimate of the parameters, but they do not account for any uncertainty in the estimated value of the parameters. 

\input{Background/back-approx-bayes-infer}